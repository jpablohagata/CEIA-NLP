{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-05 05:44:20.709068: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-05 05:44:20.709663: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-12-05 05:44:20.711669: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-12-05 05:44:20.717235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1733388260.726546   17153 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1733388260.729259   17153 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-05 05:44:20.738603: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "W0000 00:00:1733388261.576747   17153 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "import fitz\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout, Input\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "tf.config.set_visible_devices([], 'GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset el libro de Romeo y Julieta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gb39v3PaZmRH"
      },
      "outputs": [],
      "source": [
        "# Función para leer el contenido de un archivo .pdf desde una página de inicio hasta una página de finalización\n",
        "def read_pdf(file_path, start_page, end_page):\n",
        "    doc = fitz.open(file_path)\n",
        "    content = []\n",
        "    \n",
        "    # Asegurarnos de que las páginas estén dentro de los límites válidos\n",
        "    start_page = max(start_page, 0)  # Página mínima: 0 (primera página)\n",
        "    end_page = min(end_page, doc.page_count - 1)  # Página máxima: la última página\n",
        "    \n",
        "    for page_num in range(start_page, end_page + 1):\n",
        "        page = doc.load_page(page_num)  # Cargar la página\n",
        "        content.append(page.get_text())  # Obtener el texto de la página\n",
        "    \n",
        "    return \"\\n\".join(content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Texto\n",
            "0               ACTO I.\n",
            "1                     6\n",
            "2                      \n",
            "3       ESCENA PRIMERA.\n",
            "4  Una plaza de Verona.\n"
          ]
        }
      ],
      "source": [
        "# Leer el archivo .pdf desde una página de inicio hasta una página de finalización\n",
        "file_path = 'William_Shakespeare_-_Romeo_y_Julieta.pdf'\n",
        "start_page = 5  # Página de inicio\n",
        "end_page = 132   # Página de finalización\n",
        "\n",
        "text = read_pdf(file_path, start_page, end_page)\n",
        "\n",
        "# Dividir el texto en líneas y crear un DataFrame\n",
        "lines = text.split('\\n')\n",
        "df = pd.DataFrame(lines, columns=[\"Texto\"])\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               Texto\n",
            "0                                            ACTO I.\n",
            "1                                    ESCENA PRIMERA.\n",
            "2                               Una plaza de Verona.\n",
            "3        SANSON y GREGORIO, con espadas y broqueles.\n",
            "4  A fe mia, Gregorio, que no hay por qué bajar l...\n"
          ]
        }
      ],
      "source": [
        "# Filtrar registros vacíos\n",
        "df = df[df['Texto'].str.strip().ne('')]\n",
        "\n",
        "# Filtrar registros que son solo números\n",
        "df = df[df['Texto'].str.isdigit() == False]\n",
        "\n",
        "# Filtrar registros que tienen solo una palabra (sin espacios)\n",
        "df = df[df['Texto'].str.split().str.len() > 1]\n",
        "\n",
        "# Eliminar el carácter \"º\" de todos los registros\n",
        "df['Texto'] = df['Texto'].str.replace('º', '', regex=False)\n",
        "\n",
        "# Reseteo el índice\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeMpWpiyG5Ya"
      },
      "source": [
        "Consideraremos que cada secuencia para este dataset es un verso.\n",
        "\n",
        "Una de las primeras decisiones que hay que tomar es el tamaño de contexto de tokens máximo que puede consumir el modelo. Este podría ser un hiperparámetro del problema.\n",
        "\n",
        "Para elegir el tamaño de contexto máximo para este problema se puede explorar el dataset, para ello:\n",
        "- se consideran las palabras como términos.\n",
        "- se segmentará el texto de todos los versos del dataset y ses explorará la cantidad de términos presentes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "riT898QlZnmF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de documentos: 2095\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # equivalente a ltokenizer de nltk\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence # equivalente a word_tokenize de nltk\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jveeyMVKHn9J"
      },
      "outputs": [],
      "source": [
        "# cada verso lo guardamos en una lista\n",
        "text = df['Texto'].to_numpy().tolist()\n",
        "#text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "CMu9CX34J8RQ"
      },
      "outputs": [],
      "source": [
        "# segmentamos el texto con la utilidad de Keras\n",
        "segmented_sentences = [text_to_word_sequence(sentence) for sentence in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "neCJEVNvkkjE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ACTO I.'"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "duxuc-DVkcpP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['acto', 'i']"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "segmented_sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "x35rV7QZH49n"
      },
      "outputs": [],
      "source": [
        "# calculamos la longitud de cada secuencia\n",
        "length_sentences = [len(sentence) for sentence in segmented_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "R8P8vDXRII4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([198., 132., 102.,  97.,  78.,  96.,   0.,  73.,  69.,  89., 169.,\n",
              "        267., 279.,   0., 230., 150.,  51.,  11.,   3.,   1.]),\n",
              " array([ 2.  ,  2.85,  3.7 ,  4.55,  5.4 ,  6.25,  7.1 ,  7.95,  8.8 ,\n",
              "         9.65, 10.5 , 11.35, 12.2 , 13.05, 13.9 , 14.75, 15.6 , 16.45,\n",
              "        17.3 , 18.15, 19.  ]),\n",
              " <BarContainer object of 20 artists>)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# podemos ver su distribución\n",
        "plt.hist(length_sentences,bins=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_context_size: 14\n"
          ]
        }
      ],
      "source": [
        "# a partir de la distribución de longitudes de secuencias elegimos algún criterio\n",
        "# para determinar el máximo tamaño de contexto. En este caso es un percentil, pero\n",
        "# otros criterios también pueden ser válidos con la justificación adecuada.\n",
        "# También puede ser una selección \"a mano\"\n",
        "\n",
        "# el -1 es porque el último token será el target\n",
        "max_context_size = int(np.percentile(length_sentences, 90)-1)\n",
        "\n",
        "# max_context_size = int(np.ceil(np.mean(length_sentences))) # criterio de media\n",
        "# max_context_size = int(np.ceil(np.median(length_sentences))) # criterio de mediana\n",
        "print(f'max_context_size: {max_context_size}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "_XKQIpRiLNbg"
      },
      "outputs": [],
      "source": [
        "# instanciamos el tokenizador\n",
        "tok = Tokenizer()\n",
        "\n",
        "# El tokenizer \"aprende\" las palabras que se usaran\n",
        "# Se construye (fit) una vez por proyecto, se aplica N veces (tal cual un encoder)\n",
        "# El token 0 es reservado y no es asignado. Se utiliza para designar a palabras\n",
        "# fuera del vocabulario aprendido\n",
        "tok.fit_on_texts(segmented_sentences)\n",
        "\n",
        "# Convertimos las palabras a números\n",
        "# entran palabras -> salen números\n",
        "tokenized_sentences = tok.texts_to_sequences(segmented_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "AK2wfHyslrTz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[465, 1606]"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_sentences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "s-93u9lxlwlP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['acto', 'i']"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "segmented_sentences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "cSeqVGyV_wz5"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train, tokenized_sentences_val, _, _ = train_test_split(tokenized_sentences, tokenized_sentences, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmsoPbV6LxcW"
      },
      "source": [
        "Vamos a splitear las oraciones que tienen tamaño mayor al contexto máximo, para generarnos más secuencias de entrenamiento. Este paso puede obviarse si el tamaño de contexto máximo es muy grande.\n",
        "\n",
        "Por ejemplo, si tenemos el texto *La bella y graciosa moza marchóse a lavar la ropa* y nuestro contexto es de 5 palabras, tendremos:\n",
        "\n",
        "- *La bella y graciosa moza*\n",
        "- *bella y graciosa moza marchóse*\n",
        "- *y graciosa moza marchóse a*\n",
        "- *graciosa moza marchóse a lavar*\n",
        "- *moza marchóse a lavar la*\n",
        "- *marchóse a lavar la ropa*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "E5BPO4qPPnNR"
      },
      "outputs": [],
      "source": [
        "tok_sent = []\n",
        "\n",
        "for sent in tokenized_sentences_train:\n",
        "\n",
        "  # si la secuencia tiene más términos que el tamaño de contexto máximo,\n",
        "  # armo varias sub-secuencias de tamaño máximo\n",
        "  if len(sent) > (max_context_size+1):\n",
        "    extra = len(sent)-(max_context_size+1) + 1\n",
        "    for i in range(extra):\n",
        "      tok_sent.append(sent[i:i+max_context_size+1])\n",
        "  else: # si la secuencia tiene menos términos el tamaño de contexto máximo, dejo la secuencia como está\n",
        "    tok_sent.append(sent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "RiEt0AAz_64v"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1747"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tok_sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnwSC7A_LWfd"
      },
      "source": [
        "Ahora aumentamos los datos aprovechando que de una secuencia grande se pueden generar varias más pequeñas:\n",
        "\n",
        "- *La hermosa casa en el prado*\n",
        "- *La hermosa*\n",
        "- *La hermosa casa*\n",
        "- *La hermosa casa en*\n",
        "- *La hermosa casa en el*\n",
        "- *La hermosa casa en el prado*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "lWdhVV04htki"
      },
      "outputs": [],
      "source": [
        "tok_sent_augm = []\n",
        "\n",
        "for sent in tok_sent:\n",
        "\n",
        "  # generamos todas las sub-secuencias\n",
        "  subseq = [sent[:i+2] for i in range(len(sent)-1)]\n",
        "  # en esta línea paddeamos al tamaño de contexto máximo\n",
        "  tok_sent_augm.append(pad_sequences(subseq, maxlen=max_context_size+1, padding='pre'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "THXXBya1tnZ8"
      },
      "outputs": [],
      "source": [
        "# finalmente concatenamos todas las secuencias en un único array de numpy\n",
        "train_seqs = np.concatenate(tok_sent_augm, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "o5Uiflnwt10J"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15305, 15)"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_seqs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "yprwJHiMBQIS"
      },
      "outputs": [],
      "source": [
        "# y de aquí sacamos las entradas y los targets que consumirá nuestro sistema en\n",
        "# tiempo de entrenamiento\n",
        "X = train_seqs[:,:-1]\n",
        "y = train_seqs[:,1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxuKNI05Ttct"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "KFAyA4zCWE-5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15305, 14)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1D9ESMGyB_QD"
      },
      "outputs": [],
      "source": [
        "# Palabras del vocabulario\n",
        "#tok.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "WtzINYjWCMf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4431"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cantidad de palabras en el vocabulario\n",
        "vocab_size = len(tok.word_counts)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "spTBxmFQc6h8"
      },
      "outputs": [],
      "source": [
        "# El índice para cada palabra\n",
        "# El sistema las ordena de las más populares a las menos populares\n",
        "#print(tok.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nUDkjy80c77h"
      },
      "outputs": [],
      "source": [
        "# Cantidad de veces quea aparece cada palabra en cada \"documento\"\n",
        "# (1 documento = 1 caso de entrada)\n",
        "#print(tok.word_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYfhWVLLzKVO"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "5UXA5hQfWVX1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">221,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4432</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">447,632</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │       \u001b[38;5;34m221,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │        \u001b[38;5;34m60,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │        \u001b[38;5;34m80,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4432\u001b[0m)     │       \u001b[38;5;34m447,632\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">810,032</span> (3.09 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m810,032\u001b[0m (3.09 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">810,032</span> (3.09 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m810,032\u001b[0m (3.09 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# la primera capa es de embedding entrenable. Recordar que se puede variar el tamaño\n",
        "# del embedding a entrenar\n",
        "model.add(Input(shape=(None,)))\n",
        "model.add(Embedding(input_dim=vocab_size+1, output_dim=50))\n",
        "#model.add(Embedding(input_dim=vocab_size+1, output_dim=50, input_shape=(None,)))\n",
        "\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida es del tamaño del vocabulario\n",
        "model.add(Dense(vocab_size+1, activation='softmax'))\n",
        "\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "# notar que usamos la versión Sparse para utilizar sólo índices en lugar de OHE\n",
        "model.compile(loss=SparseCategoricalCrossentropy(), optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl, patience=5):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad y la paciencia para detener el entrenamiento.\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.history_ppl = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          self.model.save(\"my_model.keras\")\n",
        "          print(\"Saved new model!\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "oQq1PHDkxDvN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.3265\n",
            " mean perplexity: 2079.4311720268433 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 5.3175\n",
            "Epoch 2/20\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.4578\n",
            " mean perplexity: 2069.8524512567287 \n",
            "\n",
            "Saved new model!\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 3.4575\n",
            "Epoch 3/20\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.3952\n",
            " mean perplexity: 2193.2587631026395 \n",
            "\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 3.3952\n",
            "Epoch 4/20\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.3601\n",
            " mean perplexity: 2072.67641491796 \n",
            "\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 3.3602\n",
            "Epoch 5/20\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.3665\n",
            " mean perplexity: 2209.9000220534235 \n",
            "\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 3.3664\n",
            "Epoch 6/20\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.3431\n",
            " mean perplexity: 2426.2906789951876 \n",
            "\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 3.3432\n",
            "Epoch 7/20\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.3328\n",
            " mean perplexity: 2786.4108623985007 \n",
            "\n",
            "Stopping training...\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 3.3329\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "K30JHB3Dv-mx"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Podemos graficar la evolución de la perplejidad con las épocas.\n",
        "# Recordar que el valor de perplejidad del modelo trivial es el tamaño del vocabulario.\n",
        "epoch_count = range(1, len(history_ppl) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Rhy5hZN38qfO"
      },
      "outputs": [],
      "source": [
        "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
        "model = keras.models.load_model('my_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción de próxima palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "IBvKHFPmzpy2"
      },
      "outputs": [],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "#!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "HNyBykvhzs7-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nimport gradio as gr\\n\\ndef model_response(human_text):\\n\\n    # Encodeamos\\n    encoded = tok.texts_to_sequences([human_text])[0]\\n    # Si tienen distinto largo\\n    encoded = pad_sequences([encoded], maxlen=max_context_size, padding=\\'pre\\')\\n\\n    # Predicción softmax\\n    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\\n\\n\\n    # Debemos buscar en el vocabulario la palabra\\n    # que corresopnde al indice (y_hat) predicho por le modelo\\n    out_word = \\'\\'\\n    for word, index in tok.word_index.items():\\n        if index == y_hat:\\n            out_word = word\\n            break\\n\\n    # Agrego la palabra a la frase predicha\\n    return human_text + \\' \\' + out_word\\n\\niface = gr.Interface(\\n    fn=model_response,\\n    inputs=[\"textbox\"],\\n    outputs=\"text\")\\n\\niface.launch(debug=True)\\n'"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = tok.texts_to_sequences([human_text])[0]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario la palabra\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    for word, index in tok.word_index.items():\n",
        "        if index == y_hat:\n",
        "            out_word = word\n",
        "            break\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + ' ' + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, tokenizer, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            tokenizer (keras tokenizer): tonenizer utilizado en el preprocesamiento\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de palabras a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t  # generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t  # Tokenizamos\n",
        "      encoded = tokenizer.texts_to_sequences([output_text])[0]\n",
        "\n",
        "\t\t  # Si tienen distinto largo\n",
        "      encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t  # Predicción softmax\n",
        "      y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "      # Vamos concatenando las predicciones\n",
        "      out_word = ''\n",
        "\n",
        "      # Debemos buscar en el vocabulario la palabra\n",
        "      # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "        if index == y_hat:\n",
        "          out_word = word\n",
        "          break\n",
        "\n",
        "\t\t  # Agrego las palabras a la frase predicha\n",
        "      output_text += ' ' + out_word\n",
        "\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "JoFqRC5pxzqS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Pero no es fácil de de de de de de de de de de'"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='Pero no es fácil'\n",
        "\n",
        "generate_seq(model, tok, input_text, max_length=max_context_size, n_words=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = tok.texts_to_sequences([text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return tok.sequences_to_texts([seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "GeLqAoOYW1Hm"
      },
      "outputs": [],
      "source": [
        "# predicción con beam search.\n",
        "# Se pueden cambiar los modos entre 'det' (determinista) y\n",
        "# 'sto' (estocástico)\n",
        "# para el caso estocástico también se puede variar la temperatura\n",
        "salidas = beam_search(model,num_beams=10,num_words=6,input=\"when i find myself in times\",temp=1,mode='sto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "P8HQoLhw-NYg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 20)"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tenemos `num_beams` salidas ordenadas de mayor a menor likelihood\n",
        "salidas.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "2S3_I3S1W1Hm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i y no á que que la']"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# veamos las salidas\n",
        "decode(salidas[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Greedy Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_greedy_seq(model, tokenizer, input_text, max_length=50, n_words=10):\n",
        "    # Convertir la entrada a una secuencia de tokens\n",
        "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_length, padding='pre')\n",
        "    \n",
        "    output_text = input_text\n",
        "    \n",
        "    for _ in range(n_words):\n",
        "        # Predecir la probabilidad de la siguiente palabra\n",
        "        preds = model.predict(input_seq, verbose=0)\n",
        "        \n",
        "        # Seleccionar la palabra con la mayor probabilidad\n",
        "        next_word_idx = np.argmax(preds[0, -1, :])\n",
        "        \n",
        "        # Convertir el índice de la palabra a su correspondiente palabra\n",
        "        next_word = tokenizer.index_word[next_word_idx]\n",
        "        \n",
        "        # Agregar la palabra generada al texto de salida\n",
        "        output_text += ' ' + next_word\n",
        "        \n",
        "        # Actualizar la secuencia de entrada para incluir la nueva palabra\n",
        "        input_seq = np.concatenate([input_seq[:, 1:], np.array([[next_word_idx]])], axis=1)\n",
        "    \n",
        "    return output_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Pero no es fácil de de de de de de de de de de'"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='Pero no es fácil'\n",
        "\n",
        "generate_greedy_seq(model, tok, input_text, max_length=max_context_size, n_words=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Muestreo Aleatorio con Temperatura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_temperature_sampling(model, tokenizer, input_text, max_length=50, n_words=10, temperature=1.0):\n",
        "    # Convertir la entrada a una secuencia de tokens\n",
        "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_length, padding='pre')\n",
        "    \n",
        "    output_text = input_text\n",
        "    \n",
        "    for _ in range(n_words):\n",
        "        # Predecir las probabilidades para la siguiente palabra\n",
        "        preds = model.predict(input_seq, verbose=0)\n",
        "        \n",
        "        # Ajustar las probabilidades con la temperatura\n",
        "        preds = preds[0, -1, :]\n",
        "        preds = np.asarray(preds).astype('float64')\n",
        "        preds = np.log(preds + 1e-10) / temperature\n",
        "        preds = np.exp(preds) / np.sum(np.exp(preds))\n",
        "        \n",
        "        # Realizar un muestreo aleatorio de las probabilidades ajustadas\n",
        "        next_word_idx = np.random.choice(len(preds), p=preds)\n",
        "        \n",
        "        # Convertir el índice de la palabra a su correspondiente palabra\n",
        "        next_word = tokenizer.index_word[next_word_idx]\n",
        "        \n",
        "        # Agregar la palabra generada al texto de salida\n",
        "        output_text += ' ' + next_word\n",
        "        \n",
        "        # Actualizar la secuencia de entrada para incluir la nueva palabra\n",
        "        input_seq = np.concatenate([input_seq[:, 1:], np.array([[next_word_idx]])], axis=1)\n",
        "    \n",
        "    return output_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Pero no es fácil bajo voz has y ¡insensata cena del mi oportunamente ¡cuánto'"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text='Pero no es fácil'\n",
        "\n",
        "generate_temperature_sampling(model, tok, input_text, max_length=max_context_size, n_words=10, temperature=1.2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
